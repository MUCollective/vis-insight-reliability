---
title: "B-H for incentive calculation"
output: html_document
---

```{r setup, warning = FALSE, message = FALSE}
library(ggplot2)
library(dplyr)
library(tidybayes)
library(purrr)
library(tidyr)
library(gganimate)
library(ggrepel)
library(modelr)
library(glue)
library(forcats)
```

Purpose of this document: Using Benjamini-Hochberg to justify the FP penalty being 19. The simulation will give us the expected total payout under B-H and FP penalty = 19, so we can create a grid of $\alpha$'s and see which $alpha$ gives the highest payout. 


<!-- Previous iteration [[202011120919 Alpha level and FP penalty explainer]] -->

## Setup params

```{r}
alpha <- 0.05    # not using in simulation
K <- 20          # number of data points in a hypothesis/region
mu <- 1.5        # sample mean in a hypothesis/region
sigma <- 2.5     # ACHTUNG: mu/sd is c(1.2/3, 1.5/2.5, 1.6/2) in stimuli, 0.6 is the average
p_null <- 0.5    # the bane of my existance 
n_iter <- 1000   # number of iterations in simulation
```

## p-value PDF, CDF, invCDF defs

- Definitions of PDF and CDF from [@hung_behavior_1997]
- PDF is sampled through random draws from the uniform [0, 1] quantile space, then looked up through the inverse CDF function (`uniroot`). 

```{r}
# PDF 
f_p <- function(x, mu, sigma, K) {
  dnorm(qnorm(1 - x) - sqrt(K) * mu / sigma) / dnorm(qnorm(1 - x))
}

# CDF
F_p <- function(x, mu, sigma, K) {
  1 - pnorm(qnorm(1 - x) - sqrt(K) * mu / sigma)
}


# inverse CDF of p-value
F_p_inv <- function(q, mu, sigma, K, l = 0, u = 1){
  uniroot(function(p) F_p(p, mu, sigma, K) - q, lower = l, upper = u)$root
}

# random sample from PDF of p-value using its invCDF
rfp <- function( mu, sigma){
  q <- runif(1)
  F_p_inv(q, mu, sigma, K)
}
```


## Sampling p-values

Trying out the simulation with one $\alpha$ defined above. 

- `n_iter` of "trials" in our experiment
- For each trial, draw 8 or 12 true $\mu$ (0 or $\mu$) from $Bin(n, 1- P(null))$
- With the $\mu$ and pre-specified $\sigma$ et al., draw 8 or 12 $p$-values 
- Do the B-H and reject hypotheses/regions accordingly
- Results are `n_iter` of # of rejections under B-H, for both 8 and 12 regions

Well, the code actually compares three things

1. # rejections under B-H
2. # rejections without correction
3. The actual number of true hypotheses, the $\mu$'s sampled from the $Binomial(n, 0.5)$

```{r warning = FALSE}
(df <- expand.grid(
  nregions = c(8, 12),
  iter = 1:n_iter
) %>%
  uncount(nregions, .remove = FALSE, .id = "panel") %>%
  group_by(iter, nregions) %>%
  mutate(
    mu = mu * rbinom(nregions, 1, 1 - p_null), 
    p = map_dbl(mu, ~rfp(.x, sigma)), 
    p_bh = p.adjust(p, method = "BH"),
    reject_raw = p < alpha,
    reject_bh = p_bh < alpha
  )  %>%
  summarize(k_p_not_null_count = sum(mu != 0), 
            k_raw = sum(reject_raw),
            k_bh = sum(reject_bh), .groups = "drop_last") %>%
  pivot_longer(cols = starts_with("k_"), names_to = "method", values_to = "k")  %>%
  mutate(method = fct_relevel(method, levels = c("k_p_not_null_count", "k_raw", "k_bh")))
)

df %>%
  ggplot(aes(x = (k))) +
  geom_bar() + 
  facet_grid(method ~ nregions)
```


## Expected value of number of selections

```{r}
(expected_nselect <-
   df %>%
   group_by(nregions) %>%
   summarise(E_nselect = mean(k), .groups = "drop")
)
```

## FP penalty from utility inequality

```{r}
expected_nselect %>%
  mutate(a = (nregions - 2 * nregions * p_null + nregions * E_nselect * p_null)/(E_nselect * p_null))

```

## Alpha from maximizing payout

Given P(null), FP penalty = 19, etc., what's the $\alpha$ that maximizes the expected payout unter 


ACHTUNG: $E[n_{TP}] = E[n_{select} * P(\neg null)]$ is conservative because if people are ordering hypotheses/regions by $p$-values, the hypotheses they select should have a better chance than $P(\neg null)$ to be true. 

```{r}
(expected_payout <- expected_nselect %>%
  mutate(E_tp = E_nselect * (1 - p_null), 
         E_tn = (nregions - E_nselect) * p_null,
         E_fp = E_nselect * p_null,
         E_fn = (nregions - E_nselect) * (1 - p_null),
         E_payout = E_tp - 19 * E_fp + E_tn - E_fn)
)
```



## Grid search for the good alpha

### Encapsulate simulation function

Each call to `finding_payout` has a different $\alpha$ value. Within each call, create `n_iter` sets of p-values

```{r}
finding_payout <- function(alpha_thres){
  df <- expand.grid(
    nregions = c(8, 12),
    iter = 1:n_iter
  ) %>%
    uncount(nregions, .remove = FALSE, .id = "panel") %>%
    group_by(iter, nregions) %>%
    mutate(
      mu = rbinom(nregions, 1, 1 - p_null), 
      p = map_dbl(mu, ~rfp(.x, sigma)), 
      p_bh = p.adjust(p, method = "BH"),
      reject = p_bh < alpha_thres
    )  %>%
    summarize(k = sum(reject), .groups = "drop") 
  
  expected_nselect <-
    df %>%
    group_by(nregions) %>%
    summarize(E_nselect = mean(k), .groups = "drop")
  
  expected_payout <- expected_nselect %>%
    mutate(E_tp = E_nselect * (1 - p_null),
           E_tn = (nregions - E_nselect) * p_null,
           E_fp = E_nselect * p_null,
           E_fn = (nregions - E_nselect) * (1 - p_null),
           E_payout = E_tp - 19 * E_fp + E_tn - E_fn)
  
  expected_payout
}

```


```{r}
sim_df <- seq(from = 0.05, to = 0.5, by = 0.01) %>%
  set_names() %>%
  map_df(~finding_payout(.), .id = "alpha") 
 


sim_df %>% 
  ggplot(aes(as.numeric(alpha), E_payout)) + 
  geom_point() + 
  facet_grid(. ~ nregions)


  
```



