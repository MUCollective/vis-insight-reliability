---
title: "data analysis"
output: html_document
date: "2023-08-20"
---

```{r setup, include=FALSE}
library(tidyverse)
library(brms)
library(modelr)
library(tidybayes)
library(ggdist)
library(cowplot)
library(wesanderson)
library(bayesplot)

# set up the global theme
theme_set(theme_minimal())

# redefine the default color scheme
palette = c("#e63946", "#1d3557", "#f4a261", "#219ebc", "#8aced0", "pink")
ggplot = function(...) ggplot2::ggplot(...) + scale_color_manual(values = palette) #wes_palette("AsteroidCity1"))
```


## Introduction

In this document, we outline the data analysis steps involved. First we load the anonymised and cleaned data (the steps to which are outlined in `01-anonymise-data.Rmd`).

```{r}
solutions = read.csv("../data/final/solutions.csv") |> 
  rename(region_index = index, p_uncorrected = p)

df.responses = read.csv("../data/final/anonymised-data.csv") |> 
  inner_join(solutions, by = c("m", "trial", "region_index"))

alpha = 0.25
```


## Exploratory analysis

First, we take a look at which plots (based on the p-value) that participants are responding to as "Profitable" and which ones they are responding to as "Not Profitable". We see that participants would typically select plots corresponding to smaller p-values (sometimes even less than $\alpha = 0.25$) as "Profitable".


```{r, fig.height = 4, fig.width = 12}
df.responses |> 
  group_by(vis, user_id, response) |>
  summarise(p = list(p_uncorrected), .groups = "drop") |> 
  mutate(
    response = factor(response),
    ecdf = map(p, ecdf),
    y = list(seq(0, 1, by = 0.01)),
    x = map2(y, ecdf, ~ quantile(.y, .x))
  ) |> 
  select(-p, -ecdf) |> 
  unnest(c(x, y)) |> 
  ggplot(aes(x = x, y = y, group = user_id, colour = response)) +
  geom_line(alpha = 0.5) +
  facet_grid(response ~ vis)
```

Next, we estimate payoff for each user, in every trial. We also compute the payoff for an agent who uses an uncorrected or a Benjamini-Hochberg strategy:

```{r, fig.height = 4, fig.width = 12}
df.responses.payoff = df.responses |> 
  filter(trial != 0) |> 
  mutate(
    tp = ifelse(response == 1 & positive == 1, 1, 0),
    tn = ifelse(response == 0 & positive == 0, 1, 0),
    fp = ifelse(response == 1 & positive == 0, 1, 0),
    fn = ifelse(response == 0 & positive == 1, 1, 0)
  ) |> 
  group_by(m, vis, block, trial, user_id) |> 
  summarise_at(vars(tp, tn, fn, fp), sum) |> 
  mutate( payoff = tp*50 + tn*10 + fp*-150 + fn*-40 )

performance.by_strategy = solutions |> 
  filter(m != 8) |> 
  group_by(m, trial) |> 
  mutate(
    p_BH = p.adjust(p_uncorrected, "BH"),
    p_bonferroni = p.adjust(p_uncorrected, "bonferroni"),
    p_reject_none = 1,
  ) |> 
  pivot_longer(cols = starts_with("p_"), names_prefix = "p_", names_to = "method", values_to = "p_val") |>
  group_by(method, m, trial) |>
  mutate(
    method = ifelse(method == "uncorrected", "no correction", method),
    reject_null = p_val < alpha,
    tp = as.integer(positive & reject_null), # correctness of the decision
    fp = as.integer(!positive & reject_null),
    tn = as.integer(!positive & !reject_null),
    fn = as.integer(positive & !reject_null)
  ) |> 
  summarise_at(.vars = vars(tp, tn, fn, fp), sum)
```


In the plot below, we visualise the number of plots that participant select i.e. "mark as profitable", and compare that to the normative strategies of uncorrected, BH, bonferroni, and reject none. We see that while participants select more plots as the number of possible comparisons increases, they are selecting fewer plots compared to an uncorrected strategy but more than a perfectly executed BH strategy.

```{r}
performance.by_strategy |> 
  filter(method != "reject_none") |> 
  group_by(method, m) |> 
  summarise(selected = mean(tp + fp), .groups = "drop") |> 
  add_row(
    df.responses.payoff |> 
      group_by(m, vis) |> 
      summarise(selected = mean(tp + fp), .groups = "drop") |> 
      rename(method = vis)
  ) |> 
  mutate(m = ordered(m, levels=c(12, 16, 20))) |> 
  ggplot(aes(y = selected, x = m)) +
  geom_line(aes(group = method, colour = method)) +
  geom_point(aes(colour = method), size = 3)
```

Similarly, we see that, while participants total number of False Positives is increasing as the number of possible comparisons increases, they are making fewer False Positives when compared to an uncorrected strategy, but greater than a BH strategy would suggest.

```{r}
performance.by_strategy |> 
  filter(method != "reject_none") |> 
  group_by(method, m) |> 
  summarise(fp = mean(fp), .groups = "drop") |> 
  add_row(
    df.responses.payoff |> 
      group_by(m, vis) |> 
      summarise(fp = mean(fp), .groups = "drop") |> 
      rename(method = vis)
  ) |> 
  mutate(m = ordered(m, levels=c(12, 16, 20))) |> 
  ggplot(aes(y = fp, x = m)) +
  geom_line(aes(group = method, colour = method)) +
  geom_point(aes(colour = method), size = 3)
```
Next, we see that participants have a lower False Discovery Rate when compared to an uncorrected strategy, but greater than a BH strategy would suggest.

```{r}
performance.by_strategy |> 
  filter(method != "reject_none") |> 
  mutate(fdr = ifelse(tp+fp, fp/(tp+fp), 0)) |> 
  group_by(method, m) |> 
  summarise(fdr = mean(fdr), .groups = "drop") |> 
  add_row(
    df.responses.payoff |> 
      mutate(fdr = ifelse(tp+fp, fp/(tp+fp), 0), method = "user response") |> 
      group_by(m, vis) |> 
      summarise(fdr = mean(fdr), .groups = "drop") |> 
      rename(method = vis)
  ) |> 
  mutate(m = ordered(m, levels=c(12, 16, 20))) |> 
  ggplot(aes(y = fdr, x = m)) +
  geom_line(aes(group = method, colour = method)) +
  geom_point(aes(colour = method), size = 3)
```
Finally, we see that participants have a higher payoff when compared to an uncorrected strategy, but lower than a BH strategy would suggest.

```{r}
performance.by_strategy |> 
  filter(method != "reject_none") |> 
  group_by(method, m) |> 
  mutate(payoff = tp*50 + tn*10 + fp*-150 + fn*-40) |> 
  summarise(payoff = median(payoff), .groups = "drop") |> 
  add_row(
    df.responses.payoff |> 
      group_by(m, vis) |> 
      summarise(payoff = median(payoff), .groups = "drop") |> 
      rename(method = vis)
  ) |> 
  mutate(m = ordered(m, levels=c(12, 16, 20))) |> 
  ggplot(aes(y = payoff, x = m)) +
  geom_line(aes(group = method, colour = method)) +
  geom_point(aes(colour = method), size = 3)
```

Additionally, as participants in our study are repeating many trials, there may be potential learning or fatigue effects. We visualise participants payoff as the trials progress below:

```{r, fig.height = 4, fig.width = 12}
df.responses.payoff |> 
  ggplot(aes(x = trial, y = payoff)) +
  geom_line(aes(group = user_id), alpha = 0.1) +
  geom_smooth(method = lm, formula = 'y ~ x') +
  # geom_hline(aes(yintercept = payoff, colour = method), data = payoff.by_strategy) +
  scale_x_continuous(limits = c(1, 10), breaks = seq(1, 10, by = 1)) +
  facet_wrap(. ~ block)
```

We see that participants exhibit signs of fatigue as the progress through the trials, within each block. However, there is a confounder here, which is the the number of possible comparisons. Let us take a look at the distribution of responses for each value of `m`:

## Modeling


```{r}
df = df.responses |>
  rename( trial_id = index ) |> 
  mutate(
    tp = ifelse(response == 1 & positive == 1, 1, 0),
    tn = ifelse(response == 0 & positive == 0, 1, 0),
    fp = ifelse(response == 1 & positive == 0, 1, 0),
    fn = ifelse(response == 0 & positive == 1, 1, 0)
  ) |> 
  group_by(vis, user_id, m, block, trial_id) |> 
  summarise_at(vars(tp, tn, fn, fp), sum) |> 
  mutate(
    block = factor(block),
    nregions = factor(m),
    adj_trial_id = trial_id/5 - 1.1
  )

df$y = df %>% with(cbind(tp, tn, fn, fp)) 

select(df, -y)
```

```{r}
get_prior(
  bf(y | trials(m) ~ adj_trial_id * factor(m) * block + (adj_trial_id * factor(m) * block | user_id)),
  data = df, 
  family = multinomial()
)
```


```{r}
prior_multinom = c(
  prior(normal(0, 1.5), class = Intercept, dpar = "mufn"),
  prior(normal(0, 1.5), class = Intercept, dpar = "mutn"),
  prior(normal(0, 1.5), class = Intercept, dpar = "mufp"),
  prior(normal(0, 0.5), class = b, dpar = "mufn"),
  prior(normal(0, 0.5), class = b, dpar = "mutn"),
  prior(normal(0, 0.5), class = b, dpar = "mufp"),
  prior(lkj(2), class = cor),
  prior(normal(0, 0.5), class = sd, dpar = "mufn"),
  prior(normal(0, 0.5), class = sd, dpar = "mufp"),
  prior(normal(0, 0.5), class = sd, dpar = "mutn")
)

df$y = df %>% with(cbind(tp, tn, fn, fp)) 

fit = brm(
  bf(y | trials(m) ~ vis * nregions * adj_trial_id * block + (nregions * adj_trial_id * block | user_id)),
  data = df, 
  family = multinomial(), 
  prior = prior_multinom, 
  backend = "cmdstanr",
  cores = 4, 
  chains = 4, 
  iter = 10000, 
  warmup = 5000,
  refresh = 500,
  thin = 5,
  control = list(adapt_delta = 0.9, max_treedepth = 15),
  file = "../data/final/final-fits-minimal.rds"
)

fit
```
## Results

Note, results are going to be different if we compute estimates ignoring the trial variable, compute estimates marginalising over trials, or compute estimates conditional on a trial (say trial == 5 or trial == 10).

```{r, fig.height = 8, fig.width = 12}
datagrid_pilot = df |> 
  select(-y) |> 
  ungroup() |> 
  data_grid(vis, adj_trial_id, block, m)

draws.fit_pilot = datagrid_pilot |> 
  mutate(nregions = as.integer(m)) |> # this will probably have to change to a factor
  add_epred_draws(fit, ndraws = 1000, re_formula = NA) |> 
  group_by(vis, block, m, .row, .category, .draw) |> # this will probably need to change after the new model
  select(-nregions) |> # can get rid of this column as it is redundant
  mutate( 
    .epred = .epred / m,
    m = factor(m)
  ) # because we are estimating at a trial level where m = {12, 16, 20}
```

### Comparison of TP/TN/FP/FN rates

Note: we see block level effects, so we are marginalising over block as we are not interested in studying learning/fatigue effects.

```{r, fig.height = 8, fig.width = 12}
normative_rates = performance.by_strategy |> 
  filter(method == "BH" | method == "no correction") |>
  summarise_at(vars(tp, tn, fn, fp), mean) |> 
  mutate_at(vars(tp, tn, fn, fp), ~ ./m) |> 
  mutate(m = factor(m)) |> 
  pivot_longer(tp:fp, names_to = ".category") |> 
  pivot_wider(names_from = method, values_from = value)

draws.fit_pilot |> 
  group_by(vis, m, adj_trial_id, .draw, .category) |> 
  summarise(.epred = mean(.epred), .groups = "keep") |> 
  ggplot() +
  stat_halfeye(aes(x = .epred, y = vis), .width = 0.95) +
  geom_vline(aes(xintercept = BH), data = normative_rates, colour = "#e63946") + 
  geom_vline(aes(xintercept = `no correction`), data = normative_rates, colour = "#8aced0") +
  facet_grid(m ~ .category, scales = "free")
```
Plot when we marginalise over trials (and block):
 
```{r, fig.height = 8, fig.width = 12}
draws.fit_pilot |> 
  summarise(.epred = mean(.epred), .groups = "drop_last") |>  # marginalising over all trials
  group_by(vis, m, .draw, .category) |> 
  summarise(.epred = mean(.epred), .groups = "keep") |> 
  ggplot() +
  stat_halfeye(aes(x = .epred, y = vis), .width = 0.95) +
  geom_vline(aes(xintercept = BH), data = normative_rates, colour = "#e63946") + 
  geom_vline(aes(xintercept = `no correction`), data = normative_rates, colour = "#8aced0") +
  facet_grid(m ~ .category, scales = "free")
```
 

```{r, fig.height = 4, fig.width = 12}
normative_fdr = performance.by_strategy |> 
  filter(method == "BH" | method == "no correction") |>
  mutate(fdr = ifelse(fp + tp, fp/(fp + tp), 0)) |>  
  summarise(fdr = mean(fdr), .groups = "keep") |> 
  pivot_wider(names_from = method, values_from = fdr)

# fdr marginalised over trials and block
draws.fit_pilot |>
  filter(adj_trial_id >= 0) |> 
  group_by(m, .row, .category) |> 
  pivot_wider(names_from = .category, values_from = .epred) |> 
  mutate(fdr = ifelse((fp + tp), fp / (fp + tp), 0)) |> 
  group_by(m, vis, .draw) |>
  summarise(fdr = mean(fdr), .groups = "keep") |>
  ggplot() +
  stat_halfeye(aes(x = fdr, y = vis), .width = 0.95) +
  geom_vline(aes(xintercept = BH), data = normative_fdr, colour = "#e63946") + 
  geom_vline(aes(xintercept = `no correction`), data = normative_fdr, colour = "#8aced0") +
  facet_grid(. ~ m)
```

```{r}
normative_payoff = performance.by_strategy |> 
  filter(method == "BH" | method == "no correction") |>
  mutate(payoff = tp*50 + tn*10 + fp*-150 + fn*-40) |>  
  summarise(payoff = mean(payoff), .groups = "keep") |> 
  pivot_wider(names_from = method, values_from = payoff)

draws.fit_pilot |>
  group_by(m, .row, .category) |> 
  pivot_wider(names_from = .category, values_from = .epred) |> 
  mutate(payoff = tp*50 + tn*10 + fp*-150 + fn*-40) |> 
  group_by(m, vis, .draw) |>
  summarise(payoff = mean(payoff), .groups = "keep") |> 
  ggplot() +
  stat_halfeye(aes(x = payoff, y = vis), .width = 0.95) +
  # geom_vline(aes(xintercept = BH), data = normative_payoff, colour = "#e63946") + 
  # geom_vline(aes(xintercept = `no correction`), data = normative_payoff, colour = "#8aced0") +
  facet_grid(. ~ m)
```

