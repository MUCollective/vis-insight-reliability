---
title: "B-H for incentive calculation"
output:
  html_document:
    toc: true
    toc_depth: 2
---

```{r setup, warning = FALSE, message = FALSE}
library(ggplot2)
library(dplyr)
library(purrr)
library(furrr)
library(beepr)
library(tidyr)
library(forcats)
library(patchwork)
```

Purpose of this document: Using Benjamini-Hochberg to justify the FP penalty being 19. The simulation will give us the expected total payout under B-H and FP penalty = 19, so we can create a grid of $\alpha$'s and $P(null)$'s and see which $alpha$ gives the highest payout. 


Executive summary: under B-H, $\alpha = 0.01$ (the lowest tested on the simulation) gives the highest expected total payout. Without any correction strategy, $\alpha = 0.17 \sim 0.2$ maximizes payout.

<!-- Previous iteration [[202011120919 Alpha level and FP penalty explainer]] -->

## Setup params

```{r}
alpha <- 0.05    # not using in simulation
K <- 20          # number of data points in a hypothesis/region

# ACHTUNG: mu/sd is c(1.2/3, 1.5/2.5, 1.6/2) in stimuli, picking the average here
mu <- 1.5        # sample mean in a hypothesis/region
sigma <- 2.5     

p_null <- 0.5    # the bane of my existance 
n_iter <- 5000   # number of iterations in simulation
```

## p-value PDF, CDF, invCDF defs

- Definitions of PDF and CDF of the $p$-value from [@hung_behavior_1997]
- Random draws from the $p$-value PDF `rp` is sampled through random draws from the uniform [0, 1] quantile space, then looked up through the inverse CDF function (using `uniroot`). 
- **Limitation**: These functions are dependent on the $\mu$, $\sigma$, $K$ parameters. These parameters are most likely different IRL but we are not using other values yet.


```{r}
# PDF 
f_p <- function(x, mu, sigma, K) {
  dnorm(qnorm(1 - x) - sqrt(K) * mu / sigma) / dnorm(qnorm(1 - x))
}

# CDF
F_p <- function(x, mu, sigma, K) {
  1 - pnorm(qnorm(1 - x) - sqrt(K) * mu / sigma)
}


# inverse CDF of p-value
F_p_inv <- function(q, mu, sigma, K, l = 0, u = 1){
  uniroot(function(p) F_p(p, mu, sigma, K) - q, lower = l, upper = u)$root
}

# random sample from PDF of p-value using its invCDF
rp <- function( mu, sigma){
  q <- runif(1)
  F_p_inv(q, mu, sigma, K)
}
```


## Expected value of number of selections

We can get the expected number of selections under B-H with a few simulation iterations and take the average. Given that all the parameters, such as $\alpha$, are fixed, the uncertainty comes from the sampling of true $\mu$'s from a Binomial and the random sampling of $p$-value.


- The simulation has `n_iter` of "trials" in our experiment
- For each trial, draw 8 or 12 true $\mu$ (0 or $\mu$) from $Bin(n, 1- P(null))$
- With the $\mu$ and pre-specified $\sigma$ et al., draw 8 or 12 $p$-values 
- Do the B-H and reject hypotheses/regions accordingly
- We get the number of rejections that _should_ happen under B-H, for both 8 and 12 regions.


```{r warning = FALSE}
(df <-
  expand.grid(
  nregions = c(8, 12),
  iter = 1:n_iter
) %>%
  uncount(nregions, .remove = FALSE, .id = "panel") %>%
  group_by(iter, nregions) %>%
  mutate(
    mu = mu * rbinom(nregions, 1, 1 - p_null), 
    p_raw = map_dbl(mu, ~rp(.x, sigma)), 
    p_bh = p.adjust(p_raw, method = "BH"),
  )  %>%
  pivot_longer(starts_with("p_"), names_to = "method", values_to = "p")  %>%
  mutate(
    true = mu == 0, # null hypothesis being true
    reject = p < alpha
  ) %>%
  group_by(iter, nregions, method) %>%
  summarize( tp = sum(!true & reject),
             fp = sum(true & reject),
             tn = sum(true & !reject),
             fn = sum(!true & !reject), 
             .groups = "drop_last") %>%
  mutate(fdr =  ifelse(tp * fp != 0, (fp) / (tp + fp), 0),
         pay = (tp - 19 * fp + tn - fn) * 1) 
)
```

```{r}
df %>% 
  group_by(method) %>%
  summarize(mean(fdr))
```


Once we have the distribution of # of rejections B-H says we should make, we can take the average and get the expected value for number of selections. 

```{r}
(expected_nselect <-
   df %>%
   group_by(method, nregions) %>%
   summarise(E_nselect = mean(tp + fp), .groups = "drop")
)
```



## Expected total payout

There have been three iterations of expected total payout

1. $E[n_{FP}] = E[n_{reject}] * P(null)$. This is (even more) problematic now that we're using B-H. It can overestimate $n_{FP}$ because if people are ordering hypotheses/regions by $p$-values, they should be making false discoveries at a lower rate than $P(null)$.
2. $E[n_{FP}] = E[n_{reject}] * P(true\vert reject) = E[n_{reject}] * \alpha$. By definition, $P(true \vert reject) = E\left[\frac{n_{true \wedge  reject}}{ n_{reject}} \right]= FDR \leq \alpha$, and we say B-H controls FDR at level $\alpha$. But $\alpha$ here is an upperbound instead of the expected value, see [@benjamini_controlling_1995]. 
  - The problem is, we don't have a good expression for $E[n_{TP}]$. If we write $E[n_{TP}] = E[n_{reject}] * P(\neg true \vert reject)$, we don't have an expression for $P(\neg true \vert reject)$ like $FDR \leq \alpha$. If we just use the joint probability $E[n_{TP}] = n P(\neg true, reject)$, $P(\neg true, reject) =1 - \beta$, but there is no closed-form for power for B-H; [@benjamini_controlling_1995] had to run a simulation. So...
3. Screw it, just use the simulation results. Basically the original simulation.


```{r}
# (expected_payout <- expected_nselect %>%
#   mutate(E_tp = E_nselect * (1 - alpha),
#          E_tn = (nregions - E_nselect) * alpha,
#          E_fp = E_nselect * p_null,
#          E_fn = (nregions - E_nselect) * (1 - p_null),
#          E_payout = E_tp - 19 * E_fp + E_tn - E_fn)
# )

# (expected_payout <- expected_nselect %>%
#   mutate(E_tp = E_nselect * (1 - p_null), 
#          E_tn = (nregions - E_nselect) * p_null,
#          E_fp = E_nselect * p_null,
#          E_fn = (nregions - E_nselect) * (1 - p_null),
#          E_payout = E_tp - 19 * E_fp + E_tn - E_fn)
# )
df %>%
  group_by(method, nregions) %>%
  summarize(mean(pay))
```



## Grid search for the good alpha

Putting the above pieces together, we vary $alpha$ and $P(null)$ but keep $\mu$, $\sigma$ and $K$ the same. 

### Encapsulate simulation function

This is the same code as above

```{r}
finding_payout <- function(alpha, p_null){
  df <-
    expand.grid(
      nregions = c(8, 12),
      iter = 1:n_iter
    ) %>%
    uncount(nregions, .remove = FALSE, .id = "panel") %>%
    group_by(iter, nregions) %>%
    mutate(
      mu = mu * rbinom(nregions, 1, 1 - p_null), 
      p_raw = map_dbl(mu, ~rp(.x, sigma)), 
      p_bh = p.adjust(p_raw, method = "BH"),
    )  %>%
    pivot_longer(starts_with("p_"), names_to = "method", values_to = "p")  %>%
    mutate(
      true = mu == 0, # null hypothesis being true
      reject = p < alpha
    ) %>%
    group_by(iter, nregions, method) %>%
    summarize( tp = sum(!true & reject),
               fp = sum(true & reject),
               tn = sum(true & !reject),
               fn = sum(!true & !reject), 
               .groups = "drop_last") %>%
    mutate(fdr =  ifelse(tp * fp != 0, (fp) / (tp + fp), 0),
           pay = (tp - 19 * fp + tn - fn) * 1,
           power = (tp)/(tp + fn)) # this produces NA's; set to 1?
  
df %>%
  group_by(method, nregions) %>%
  summarize(E_pay = mean(pay), 
            E_fdr = mean(fdr), 
            power = mean(power), .groups = "drop")
}

```

setting seed https://davisvaughan.github.io/furrr/articles/articles/gotchas.html#argument-evaluation

```{r, eval= FALSE}
plan(multisession, workers = 5)
options <- furrr_options(seed = 123)


(sim_df <- expand.grid(
    alpha = seq(from = 0.01, to = 0.5, by = 0.01),
    p_null = ppoints(20)
  ) %>%
    split(1:nrow(.)) %>%
    future_map_dfr(~cbind(.x, finding_payout(.$alpha, .$p_null), row.names = NULL), .options = options)
)

beep()
saveRDS(sim_df, "sim_n5000_alpha_pnull.rds")
```
```{r}
sim_df <- readRDS("sim_n5000_alpha_pnull.rds")
```

### Results

```{r}
sim_df %>% 
  ggplot(aes(p_null, E_pay, color = alpha)) + 
  geom_point(alpha = 0.2) + 
  geom_line(data = sim_df %>% filter(alpha == 0.05)) + 
  facet_grid(nregions ~ method) + 
  scale_color_viridis_c() + 
  theme_minimal()  +
  labs(title = "Which alpha maximizes payout?", subtitle = "Line drawn at alpha = 0.05")
```


```{r}
sim_df %>% 
  filter(alpha < 0.2 & method != "p_raw") %>%
  ggplot(aes(p_null, E_pay, color = alpha)) + 
  geom_point(alpha = 0.2) + 
  geom_line(data = sim_df %>% filter(alpha == 0.05 & method != "p_raw")) + 
  facet_grid(nregions ~ method) + 
  scale_color_viridis_c() + 
  theme_minimal()  +
  labs(title = "Which alpha maximizes payout?", subtitle = "Line drawn at alpha = 0.05")
```
  
```{r}
sim_df %>% 
  ggplot(aes(alpha, E_pay, color = p_null)) + 
  # geom_point(alpha = 0.2) +
  geom_line(aes(group = p_null), alpha = 0.5)  +
  # geom_line(data = sim_df %>% filter(p_null %in% c(0.025, 0.475, 0.975)), aes(group = p_null)) + 
  facet_grid(nregions ~ method) + 
  scale_color_viridis_c() + 
  theme_minimal() +
  labs(title = "Which alpha maximizes payout?", subtitle = "alpha = 0.01 for B-H, 0.18 for raw?")
```
```{r}
sim_df %>%
  group_by(nregions, method) %>%
  slice_max(E_pay)
```




```{r}
sim_df %>%
  ggplot(aes(alpha, E_fdr, color = p_null)) +
  geom_point(alpha = 0.2) + 
  geom_line(data = sim_df %>% filter(p_null == 0.475)) +
  geom_abline(aes(intercept = 0, slope = 1)) + 
  facet_grid(. ~ method) + 
  scale_color_viridis_c() + 
  theme_minimal() + 
  labs(title = "FDR under B-H and raw strategy", subtitle = "Diagonal line is alpha = FDR, colored line at P(null) = 0.5")
```


```{r}
sim_df %>%
  ggplot(aes(alpha, power)) + 
  geom_point(aes(color = p_null), alpha = 0.2) + 
  geom_vline(aes(xintercept = 0.05)) +
  geom_hline(aes(yintercept = 0.8)) +
  facet_grid(nregions ~ method) +
  scale_color_viridis_c() + 
  theme_minimal() +
  labs(title="Power is higher without correction", subtitle = "A bunch of NA's for when P(null) is high")
```

## Comparing simulation to experimental stimuli data


```{r}
data.sim.12reg <- readRDS(file = "../data/simulated_data_12regions.rds")
data.sim.8reg <- readRDS(file = "../data/simulated_data_8regions.rds")

(df_stimuli <- bind_rows(
  list("12" = data.sim.12reg, "8" = data.sim.8reg), 
  .id = "nregions") %>%
  select(-c(region_idx, effect_size, population, p_h1)) %>%
  mutate(nregions = as.numeric(nregions))
)
```

```{r}
stimuli_fn <- function(df_stimuli, alpha){
  df_stimuli %>%
    mutate(p_raw = 
             map_dbl(data, ~ t.test(.x, alternative = "greater")$p.value)) %>%
    group_by(nregions, trial) %>%
    mutate(p_bh = p.adjust(p_raw, "BH")) %>%
    select(-data) %>%
    pivot_longer(starts_with("p_"), names_to = "method", values_to = "p") %>%
    mutate(reject = p < alpha,
           true = mu == 0) %>%
    group_by(trial, nregions, method) %>%
    summarize( tp = sum(!true & reject),
               fp = sum(true & reject),
               tn = sum(true & !reject),
               fn = sum(!true & !reject), 
               .groups = "drop_last") %>%
    mutate(fdr =  ifelse(tp * fp != 0, (fp) / (tp + fp), 0),
           pay = (tp - 19 * fp + tn - fn) * 1,
           power = (tp)/(tp + fn)) %>% # this produces NA's; set to 1?
    group_by(nregions, method) %>%
    summarize(E_pay = mean(pay), 
              E_fdr = mean(fdr), 
              power = mean(power), .groups = "drop")
}

```

```{r}
stimuli_alpha_df <- expand.grid(alpha = seq(from = 0.01, to = 0.5, by = 0.01)) %>%
  split(1:nrow(.)) %>%
  map_dfr(~ cbind(.x, stimuli_fn(df_stimuli, .$alpha), row.names = NULL))
```

```{r}
(p1 <- stimuli_alpha_df %>%
  ggplot(aes(alpha, E_pay)) + 
  geom_point() + 
  facet_grid(nregions ~ method) +
  scale_color_viridis_c() + 
  theme_minimal() +
  labs(title = "t-test on experiment stimuli", subtitle = "P(null) = 0.5")
)
```

```{r}
(p2 <- sim_df %>% 
  filter(p_null == 0.475) %>%
  ggplot(aes(alpha, E_pay)) + 
  # geom_point(alpha = 0.2) +
  geom_point()  +
  # geom_line(data = sim_df %>% filter(p_null %in% c(0.025, 0.475, 0.975)), aes(group = p_null)) + 
  facet_grid(nregions ~ method) + 
  scale_color_viridis_c() + 
  theme_minimal() +
  labs(title = "Simulation results")
)
```

```{r}
p1 + p2 
```

